## 大纲

- 顺序一致性(sequential consistency)
- 无锁互斥
- 宽松内存一致性模型（RELAXED MEMORY CONSISTENCY）
- CAS
- 无锁算法（LOCK-FREE ALGORITHMS）
- ABA问题

这部分内容，非常难，但也非常有趣

----

## 顺序一致性

Ex: Initially,  a = b = 0;

```assembly
; 处理器0
mov 1, a   ; Store
mov b, %ebx ; Load
; 处理器1
mov 1, b  ; Store
mov a, %eax ; Load
```

> 有没有一种可能，就是在这些处理器都执行完他们的代码后，P0的%ebx和P1的%eax都包含0值，

则取决于**内存模型**： 在并行计算上内存操作行为是怎么样的。

顺序一致性是是一致性的最标准的的一种， 我们接下来看什么是顺序一致性。

> [!NOTE]
>
> 任何执行的结果都与所有处理器的操作按某个顺序执行的结果相同，并且每个处理器的操作按其程序指定的顺序出现在这个序列中    by  Leslie Lamport [1979]

- 一个处理器程序定义的指令序列与其他处理器程序定义的相应序列**交错**，以生成所有指令的全局**线性顺序**。
- 根据该线性顺序，LOAD指令接收的值，来源于由最近的、且在LOAD指令之前的STORE指令存储到某个地址的
- 硬件可以执行任何操作，但为了使执行保持顺序一致性，它必须表现得像是LOAD和STORE遵循某种全局线性顺序。

回到刚刚的例子，我们把四个语句标号，他们的交错结果，以及最终产生的值的比较如图

![截屏2024-06-27 03.48.01](/Users/mac/Library/Application%20Support/typora-user-images/%E6%88%AA%E5%B1%8F2024-06-27%2003.48.01.png)

顺序一致性揭示了没有一种执行结果满足 %eax = %ebx = 0的

----

**推断顺序一致性**

- 执行带来了一种“**发生在之前**”（happens before) 的关系，我们可以用``->``表示

- ``->``的关系是是**线性**的，意味着对于两个不同的指令x, y要么是``x->y``要么是``y->x``
- ``->``的关系遵循处理器顺序，即每个处理器中指令的顺序
- 内存中的某个位置的 LOAD 操作读取的值， 来自``->``关系最近的 STORE 操作写入的值

- 要使执行后的内存达到顺序一致性，必须存在这样的``->``的线性顺序，使得内存状态成立

---

## 无锁互斥

并发理论早期最著名成果之一，无需锁也能实现互斥。

**回顾**

临界区是访问共享数据结构的代码片段，这些数据结构不允许同时被两个或多个线程访问（互斥访问）。 互斥锁大部分实现会利用原子操作指令，确保对锁的获取（加锁）和释放（解锁）是原子的、不可分割的操作。例如

- **xchg**：交换操作，可以原子地交换寄存器和内存中的值
- **test-and-set**：测试并设置操作，用于原子地设置锁的状态
- **compare-and-swap**：比较并交换操作，原子地比较内存中的值与预期值，如果相等则交换
- **load-linked-store-conditional**：加载链接-存储条件操作，用于实现乐观锁（optimistic locking)

虽然锁能解决临界区的问题，但是引入了一些问题——死锁，护航效应(convoying)



> 互斥可以仅仅通过使用LOAD和STORE这些内存操作来实现？

Theodorus J. Dekker 和 Edsgar Dijkstra 展示了这是可以做到的，只要计算机系统是顺序一致的。

但是这里不讲解，因为它足够复杂。我们该用比较简单且优雅的方法表达他们的想法。用Peterson'算法。

Alice想玩弄这个称为x小物件，而Bob想将它放好，但是小物件并不能同时满足，所以他们是互斥。他们将重复不断执行各自的代码。

![截屏2024-06-27 04.15.57](/Users/mac/Library/Application%20Support/typora-user-images/%E6%88%AA%E5%B1%8F2024-06-27%2004.15.57.png)

直觉上看，

- 如果Alice和Bob都试图进入临界区域，那么最后写入的那个会自旋，而另一个会继续执行
- 如果只有Alice试图进入临界区域，那么她会继续执行，因为B_wants为false
- 如果只有Bob试图进入临界区域，那么他会继续执行，因为B_wants为false

> [!IMPORTANT]
>
> Perterson's 算法实现了临界区的互斥

证明方法： 

- 假设为了反证，Alice和Bob都同时进入了临界区域。
- 考虑他们进入临界区域之前各自的最新时间点(the most-recent time)
- 我们将推导出一个矛盾。

![截屏2024-06-27 04.35.17](http://198.46.215.27:49153/i/667c7b949cb9f.png)

- 不失一般性， 假设Bob是最后写入turn的： write_A(turn = B) -> write_B(turn = A)
- Alice的程序顺序是：write_A(A_wants = true) -> write_A(turn = B)
- Bob的程序顺序是：write_B(turn = A) -> read_B(A_wants) -> read_B(turn)
- Bob实际读到了什么？ 
  - A_wants: A; turn: A =>  Bob应该子旋。

与前提矛盾，证毕。

> [!IMPORTANT]
>
> Peterson's算法保证了饥饿自由: 当Alice想要执行临界区，Bob不能重复在临界区执行两次，反之亦然。

> 顺序一致性的唯一问题是什么？ 

到目前为为止， 没有机器支持顺序一致性。

----

## 宽松内存一致性模型

> [!IMPORTANT]
>
> Never synchronize through memory. 千万不要用内存来同步
>
> （因为很难做到正确）

当代内存模型现状

- ∙ 当代的处理器没有实现顺序一致性。
-  所有处理器都实现了某种形式的宽松一致性。
-  硬件会主动重新排序指令。 
- 编译器也可能重新排序指令。

---

**指令重排序**



![截屏2024-06-27 05.04.53](/Users/mac/Library/Application%20Support/typora-user-images/%E6%88%AA%E5%B1%8F2024-06-27%2005.04.53.png)

> 为什么硬件和编译器决定重排序这些指令？为什么硬件更喜欢先做load操作？

为了通过掩盖加载延迟（load latency）来获得更高的性能——指令级并行性。这种优化可以使处理器在等待某些指令的执行结果时，不必闲置，而是继续执行其他不依赖于这些结果的指令

> 对于硬件或者编译器而言，什么情况下进行的指令重排序可视为安全的

1. 当 a  != b
2. 并且没有并发访问

----

**硬件重排序**

在内存总线上，处理器可以非常快速地发出存储指令（STORE），总线（网络）处理比较慢，因此使用了存储缓冲区(store buffer)来解决存储指令和网络速度不匹配的问题。

![截屏2024-06-27 12.22.37](http://198.46.215.27:49153/i/667ce91c8ca65.png)

由于加载（LOAD）指令可能会使处理器停顿直到加载完成（每当你执行LOAD指令时，如果这个数据不在处理器的缓存中，处理器将不得不等待内存子系统返回数据） ，因此LOAD指令优先于STORE指令，可以绕过存储缓冲区。

![截屏2024-06-27 12.31.47](http://198.46.215.27:49153/i/667ceb3b9a8a8.png)

这样会有什么问题？ 就是如果LOAD的地址刚好是在STORE缓冲区的。如果LOAD指令的地址与存储缓冲区中的地址匹配，则存储缓冲区会返回结果

![截屏2024-06-27 12.38.09](http://198.46.215.27:49153/i/667cecc0995be.png)

因此，总的来说加载指令可以绕过存储到不同地址的存储指令.

---

**x86-64 完全存储定序(Total Store Order)** 

> [!NOTE]
>
> 加载（LOAD）指令不会与其他加载指令重排序。
>
> 存储（STORE）指令不会与其他存储指令重排序。
>
> 存储（STORE）指令不会与之前的加载（LOAD）指令重排序。换句话说你永远不会将存储指令提前到加载指令之前
>
> 加载（LOAD）指令可以与之前的指令存储（STORE）重排序，但不能与相同地址的存储（STORE）指令重排序。这就是前面提到的， A != B 
>
> 加载（LOAD）和存储（STORE）指令都不会与锁（LOCK）指令重排序。
>
> 对相同地址的存储（STORE）指令遵循全局总顺序(global total order)。
>
> 加锁指令遵循全局总顺序。
>
> 内存排序保留传递可见性（因果性）。

我们举个例子说明。

![截屏2024-06-27 12.49.04](http://198.46.215.27:49153/i/667cef4b44370.png)

> Load 5 可以和 Load 4交换吗？

No

> Store1可以和Store2交换吗？

No

> Store3可以和Load2交换吗？

No

最终重排序之后的结果。 **TSO一致性比顺序一致性要弱一些**

![截屏2024-06-27 13.06.36](http://198.46.215.27:49153/i/667cf365b5b40.png)

----

**重排序的影响**

回到最开始的例子。



 ![截屏2024-06-27 13.47.16](http://198.46.215.27:49153/i/667cfcf1c69f2.png)

,如果按照<2, 4, 1, 3>的顺序，将产生 %eax = %ebx = 0，我们说**指令重排序违背了顺序一致性**， 这不仅会发生在硬件重排序，还有可能发生在编译重排序上。这就要求我们

> [!IMPORTANT]
>
> Nerver write non-determisitic code 
>
> 永远不要写不确定的代码

**重排序对Perterson‘s 算法的影响**

![截屏2024-06-27 13.55.29](http://198.46.215.27:49153/i/667cfee969052.png)

B_wants和A_wants的LOAD指令可能重排序到A_wants和B_wants的Store指令前面，最终可能导致Alice和Bob同时进入临界区！

---

**内存屏障**

内存栅栏（或内存屏障）是一种硬件操作，它强制执行指令序列中的顺序约束，确保在栅栏之前和之后的指令按照预期顺序执行。

**显式内存栅栏**：可以通过特定的指令来显式地发出（例如x86架构中的mfence指令），用于确保栅栏之前和之后的内存操作的顺序关系。

**隐式内存栅栏**：某些同步指令（如locking、exchanging等）会隐式执行内存栅栏操作，以保证操作的顺序性。

例如，Tapir/LLVM编译器通过在C语言头文件stdatomic.h中定义的atomic_thread_fence()函数实现内存栅栏。这种函数调用会生成对应平台的适当指令序列，以确保相关内存操作的顺序性。

内存栅栏的典型成本与L2缓存访问的成本相当，通常是为了确保多核处理器或多线程环境下的内存操作的一致性和正确性而引入的。通过使用内存栅栏，程序员可以控制和优化程序中的内存访问顺序，避免数据竞争和不确定的行为。 

我们要知道，系统都是人类做的，人们通过benchmark代码跑出的结果来判断并行计算的性能，那我也可以将锁的性能做的比内存屏障还要好。

**Peterson‘s的例子恢复一致性**

![截屏2024-06-27 14.14.23](http://198.46.215.27:49153/i/667d034adb1c8.png)

你还需要确保编译器不会把你搞砸。

----

![截屏2024-06-27 14.40.39](http://198.46.215.27:49153/i/667d097d231a2.png)

过去在使用内存屏障（memory fence）时的额外注意事项

1. 在过去，为了防止编译器优化掉内存引用，必须将变量声明为 `volatile`。`volatile` 关键字告诉编译器，该变量的值可能随时会被外部因素改变，因此每次引用都必须从内存中读取，而不是依赖于寄存器中的缓存值。
2. 你需要在``frob()``和``borf()``放置编译器屏障来阻止被编译器重排序

---

**用C11恢复一致性**

C11语言标准定义了自己的弱内存模型，通过以下方式可以控制硬件和编译器对内存操作的重新排序：

1. **声明变量为_Atomic**：在C11标准中，可以通过声明变量为 `_Atomic` 类型来指示编译器该变量是原子类型，需要进行原子操作。原子类型的变量可以保证在多线程或并发环境中，其操作是原子的，即不会被中断或重排序。
2. **使用原子函数**：C11标准提供了一系列的原子操作函数，例如 `atomic_load()`、`atomic_store()` 等。这些函数能够确保对原子类型变量的读取和写入是原子性的，不会被硬件或编译器进行重新排序或优化。

通过这些机制，开发者能够更精确地控制内存操作的执行顺序和可见性，确保多线程或并发程序的正确性和可靠性

![截屏2024-06-27 14.44.01](http://198.46.215.27:49153/i/667d0a3e2cbce.png)

---

**实现通用的锁**

> [!NOTE]
>
> Thm1 [Burns-Lynch] 
>
> 任何仅使用LOAD和STORE内存操作的n线程不发生死锁的互斥算法都需要Ω(n)的空间。（这个定理突显了使用简单的内存操作来实现复杂的并发控制是非常昂贵的）
>
> The2 [Attiya et al.] 
>
> 在现代计算机上，任何n线程不发生死锁的互斥算法必须使用类似内存屏障或原子比较交换这样昂贵的操作。这些操作确保了多线程环境中的数据一致性和操作的原子性，避免了竞态条件和数据污染问题

因此，硬件设计者在支持这些特殊操作时是合理的。这些操作不仅确保了程序在并发执行时的正确性和可靠性

---

## CAS

 **无锁工具**

- 内存操作
  - LOAD
  - STORE
  - CAS(compare-and-swap)

---

**Compare-and-Swap**

由 x86-64 架构上的 `cmpchg` 指令提供。C 语言的头文件 `stdatomic.h` 通过内置函数 `atomic_compare_exchange_strong()` 提供了 CAS（Compare-And-Swap），该函数可以对各种整数类型进行操作。CAS做的事情是，检查下该内存地址上的值与旧值相同，相同则将内存地址的值改成新值返回true，否则直接返回false;

```c
// 规范
bool CAS(T *x, T old, T new) {
  if (*x == old) {
    *x = new;
    return ture
  }
  return false;
}
```

- 原子执行
- 隐式屏障

---

**用CAS实现互斥锁**

用CAS实现n线程无死锁的互斥算法，可使用θ(1)来实现

证明

```c
void lock(int *lock_var) {
  while (!CAS(*lock_var, false, true)) // 自旋锁
}

void unlock(int *lock_var) {
  *lock_var = false;
}
```

---

**例子分析：累加问题**

```c
int compute(const X& v);
int main() {
  const int n = 1000000;
  extern X myArray[n];
  // ...
  int result = 0;
  cilk_for(int i = 0; i < n; ++i) {
    result += compute(myArray[i]); // note: 这里有竞态数据
  }
  printf("The result is: %f\n", result);
  return 0;
}

```

常规的互斥锁解法

```c
int compute(const X& v);
int main() {
  const int n = 1000000;
  extern X myArray[n];
  mutex L;
  // ...
  int result = 0;
  cilk_for(int i = 0; i < n; ++i) {
    L.lock();
    result += compute(myArray[i]); // note: 这里有竞态数据
    L.unlock();
  }
  printf("The result is: %f\n", result);
  return 0;
}
```

> 一个循环获取了锁以后，如果OS此时将迭代swap出去了，会发生什么？

所有的循环迭代都必须等待

在这个例子中，我们想要的达到的效果是，执行完对x的LOAD操作后自动执行STORE操作

---

**CAS的解法**

```c
int result = 0;
clik_for(int i = 0; i < n; i++) {
  int temp = compute(myArray[i]);
  int old, new;
  do {
    old = result;
    new = old + temp;
  } while (!CAS(&result, old, new));
}
```

---

## **无锁算法TODO**

无锁栈

```c
struct Node {
  Node* next;
  int data;
};
struct Stack {
  Node* head
}
```

![截屏2024-06-28 14.17.56](http://198.46.215.27:49153/i/667e559c75f1f.png)无锁push

```c
void push(Node* node) {
  do {
    node->next = head;
  } while (!CAS(&head, node->next, node))
}
```

如果



---

## ABA问题